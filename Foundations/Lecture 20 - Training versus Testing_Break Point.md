## Trainng versus Testing

### Break point

* If growth function is polynomial then p(bad event) will be reduced, the equation will be decreased faster (ex: positive ray or positive intervals)
* If exponential of convex sets is increased then p(bad event) would be bigger even exp can reduce the equation
<br>![image](https://github.com/yhlien1221/Machine_Learning_Foundations_and_Techniques/blob/main/Foundations/pic/20_1.jpg)<br/>
<br><br/>
* Break Point: When the number of input in a certain extent, the k th input won't be shattered and can't deal with all combinations (mh(N)<2 to the power of N), then the k point is called **break point**
* For example, in 2D perceptrons, 3 inputs has 2 to the power of 3 dichotomies, but dichotomies of 4 inputs will be less than 2 to the power of 4
<br>![image](https://github.com/yhlien1221/Machine_Learning_Foundations_and_Techniques/blob/main/Foundations/pic/20_2.jpg)<br/>
<br><br/>
* Does break point only happen in <br>![image](https://github.com/yhlien1221/Machine_Learning_Foundations_and_Techniques/blob/main/Foundations/pic/20_4.jpg)<br/>?
* We can suggest that growth speed of 2D perceptron is <br>![image](https://github.com/yhlien1221/Machine_Learning_Foundations_and_Techniques/blob/main/Foundations/pic/20_5.jpg)<br/>
<br>![image](https://github.com/yhlien1221/Machine_Learning_Foundations_and_Techniques/blob/main/Foundations/pic/20_3.jpg)<br/>

 
## Reference:
1. Hsuan-Tien Lin - Machine Learning Foundations (機器學習基石)

<!-- ref
http://naivered.github.io/2016/08/13/Study_Notes/Machine%20Learning%20Foundations/Machine-Learning-Foundations-L5-Notes-1/
https://cynthiachuang.github.io/Machine-Learning-Foundations-Study-Notes-Mathematical-Foundations-Week2/?view
-->
