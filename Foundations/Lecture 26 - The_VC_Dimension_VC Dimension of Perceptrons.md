## The VC Dimension

### VC Dimension of Perceptrons
* 2D PLA algorithms:
- Perceptrons k = 4, dvc = 3
- N is large enough, Eout(g) is approximate Ein(g)
- if there is a g that make Ein(g) approximate 0 (PLA learned)
<br>[image](https://github.com/yhlien1221/Machine_Learning_Foundations_and_Techniques/blob/main/Foundations/pic/26_1.jpg)<br/>
<br><br/>
* Below is the proof of VC Dimension of PLA is "d+1"
<br>[image](https://github.com/yhlien1221/Machine_Learning_Foundations_and_Techniques/blob/main/Foundations/pic/26_2.jpg)<br/>
<br><br/>
<br>[image](https://github.com/yhlien1221/Machine_Learning_Foundations_and_Techniques/blob/main/Foundations/pic/26_3.jpg)<br/>
<br><br/>
<br>[image](https://github.com/yhlien1221/Machine_Learning_Foundations_and_Techniques/blob/main/Foundations/pic/26_4.jpg)<br/>
<br><br/>
<br>[image](https://github.com/yhlien1221/Machine_Learning_Foundations_and_Techniques/blob/main/Foundations/pic/26_5.jpg)<br/>
<br><br/>

## Reference:
1. Hsuan-Tien Lin - Machine Learning Foundations (機器學習基石)

<!-- ref
https://qiubite31.github.io/2017/08/16/Machine-Learning-Foundation-7/
https://medium.com/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E5%9F%BA%E7%9F%B3%E7%B3%BB%E5%88%97/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E5%9F%BA%E7%9F%B3-4-vc-dimension%E5%92%8C%E6%A8%A1%E5%9E%8B%E8%A4%87%E9%9B%9C%E5%BA%A6-5398ed1c8a5e
https://iter01.com/92.html
https://johnnyasd12.gitbooks.io/machine-learning-ntu/content/ji-qi-xue-xi-ji-shi/week7-vc-dimension.html
-->
